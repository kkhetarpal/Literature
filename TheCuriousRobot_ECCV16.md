Most of the current methods to learn visual representations use passive observations such as images, and videos which are labeled for supervised learning. On the other hand, biological agents use active physical-interactions with the world to learn visual representations. This work introduces a system on a Baxter platform that uses four different type of interactions:
* Pushing
* Grasping
* Tactile Sensing (Touching and Poking)
* Identity Vision

